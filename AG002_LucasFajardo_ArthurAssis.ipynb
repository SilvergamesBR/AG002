{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474b5866-383d-4449-ac89-6f85ae7414d5",
   "metadata": {},
   "source": [
    "# AG002 - Lucas Fajardo de Mello (GES - 171) e Arthur de Paula Assis (GES - 122)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e684901-89c8-437e-94c5-075c46751baa",
   "metadata": {},
   "source": [
    "Para começarmos a AG primeiramente temos que carregar o nosso dataset, para isso vamos utilizar a biblioteca pandas, com a função read_csv.\n",
    "\n",
    "Vamos também importar algumas bibliotecas que utilizaremos depois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69bad24b-cacc-48d8-8365-e4f7c83a648b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicatessen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Other</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Other</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Other</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HoReCa</td>\n",
       "      <td>Other</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Other</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicatessen\n",
       "0  Retail  Other  12669  9656     7561     214              2674          1338\n",
       "1  Retail  Other   7057  9810     9568    1762              3293          1776\n",
       "2  Retail  Other   6353  8808     7684    2405              3516          7844\n",
       "3  HoReCa  Other  13265  1196     4221    6404               507          1788\n",
       "4  Retail  Other  22615  5410     7198    3915              1777          5185"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"Dataset/Wholesale customers data.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d643fe1-b3d2-40ba-80ab-f9993ae460c4",
   "metadata": {},
   "source": [
    "## Ex 3\n",
    "\n",
    "Nesse exercício nós trocamos os \"rótulos\" de Canal e Região por valores inteiros, facilitando futuros processos ao manejar o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d92a3131-d769-4883-bead-58554aad0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArthurPC\\AppData\\Local\\Temp\\ipykernel_7036\\2407502995.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset.Channel.replace({\"HoReCa\":0,\"Retail\":1}, inplace = True) #Altera os valores HoReCa e Retail para 0 e 1\n",
      "C:\\Users\\ArthurPC\\AppData\\Local\\Temp\\ipykernel_7036\\2407502995.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset.Channel.replace({\"HoReCa\":0,\"Retail\":1}, inplace = True) #Altera os valores HoReCa e Retail para 0 e 1\n",
      "C:\\Users\\ArthurPC\\AppData\\Local\\Temp\\ipykernel_7036\\2407502995.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset.Region.replace({\"Lisbon\":0,\"Oporto\":1,\"Other\":2}, inplace = True) #Altera os valores Lisbon, Oporto e Other para 0, 1 e 2\n",
      "C:\\Users\\ArthurPC\\AppData\\Local\\Temp\\ipykernel_7036\\2407502995.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset.Region.replace({\"Lisbon\":0,\"Oporto\":1,\"Other\":2}, inplace = True) #Altera os valores Lisbon, Oporto e Other para 0, 1 e 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicatessen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  \\\n",
       "0        1       2  12669  9656     7561     214              2674   \n",
       "1        1       2   7057  9810     9568    1762              3293   \n",
       "2        1       2   6353  8808     7684    2405              3516   \n",
       "3        0       2  13265  1196     4221    6404               507   \n",
       "4        1       2  22615  5410     7198    3915              1777   \n",
       "\n",
       "   Delicatessen  \n",
       "0          1338  \n",
       "1          1776  \n",
       "2          7844  \n",
       "3          1788  \n",
       "4          5185  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Channel.replace({\"HoReCa\":0,\"Retail\":1}, inplace = True) #Altera os valores HoReCa e Retail para 0 e 1\n",
    "\n",
    "dataset.Region.replace({\"Lisbon\":0,\"Oporto\":1,\"Other\":2}, inplace = True) #Altera os valores Lisbon, Oporto e Other para 0, 1 e 2\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d5ed8-d1e3-4a8c-a68b-4a8972a17555",
   "metadata": {},
   "source": [
    "## Ex 4\n",
    "\n",
    "Nesse exercício iremos mudar a ordem das colunas do nosso dataframe, para isso iremos utilizar um artifício onde ao chamarmos um dataframe com uma lista das colunas desejadas em uma certa ordem o pandas retorna um dataframe com as colunas nessa mesma ordem, assim podemos atribuir esse dataframe reordenado ao original, assim o reorganizando sem a necessidade de chamadas de função mais complexas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89393cc-365f-4532-be68-aa1622208154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicatessen</th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicatessen  \\\n",
       "0       2  12669  9656     7561     214              2674          1338   \n",
       "1       2   7057  9810     9568    1762              3293          1776   \n",
       "2       2   6353  8808     7684    2405              3516          7844   \n",
       "3       2  13265  1196     4221    6404               507          1788   \n",
       "4       2  22615  5410     7198    3915              1777          5185   \n",
       "\n",
       "   Channel  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novaOrdem =['Region', 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicatessen', 'Channel'] #Estabelecemos um array um com os valores na ordem nova dessejada\n",
    "\n",
    "dataset = dataset [novaOrdem] #Altera a ordem para a nova ordem desejada\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d725d-686d-4993-97bd-eb92c9baab57",
   "metadata": {},
   "source": [
    "## Ex 5\n",
    "\n",
    "Nesse exercício iremos separar nosso dataset em uma seção de teste e outra para treinos do nosso modelo de ML, iremos utilizar um split de 80/20.\n",
    "\n",
    "Para realizar essa divisão utilizaremos a função train_test_split do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d7be87b-9149-4d57-a3f5-4968356af120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3c873-395d-4950-bbe7-756e1e2cb1b7",
   "metadata": {},
   "source": [
    "## Ex 6 \n",
    "\n",
    "Nesse exercício iremos escolher um modelo de ML, decidimos por escolher o modelo Naive Bayes, por ser um modelo simples baseado em matemática e ser amplamente utilizado para predições similares no contexto de varejo.\n",
    "\n",
    "Antes de treinar o nosso modelo, também vamos utilizar um algoritmo de Forward Selection com K-fold cross validation para escolher apenas as features que terão um impacto significativo no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb73af27-2dce-4625-81ad-ad43ee9961a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def K_fold_validation_scoring(model,X,y,scoring:str):\n",
    "    scores = cross_val_score(model, X, y, cv=10,scoring=scoring)#Faz 10-fold cross validation e retorna as pontuações de NRMSE\n",
    "    return scores.mean()#retorna a média de pontuação do NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1128d347-7643-48f7-8a91-dd60052d79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_selection_cross_validation(X,y,features,minScoreVariation : float,detailedOutput : bool,scoring : str,model):\n",
    "    used_features=[]#lista para armazenar as features que devem ser usadas no modelo, de acordo com o forward selection \n",
    "    unused_features = list(features)#inicialmente lista todas as features disponíveis para o modelo, porém, ao final, conterá as features não usadas\n",
    "    current_score = float('-inf')#variável para armazenar a pontuação do modelo atual\n",
    "    best_current_score = float('-inf')#variável para armazenar a melhor pontuação registrada\n",
    "\n",
    "    while current_score == best_current_score and unused_features:\n",
    "        score_for_feature = []#lista para armazenar a pontuação obtida com cada feature\n",
    "        for feature in unused_features:#faz uma iteração para cada feature não utilizada, além de realizar o 10-fold cross validation para cada uma\n",
    "            current_features = used_features + [feature]\n",
    "            model.fit(X=X[current_features],y=y)\n",
    "            score = K_fold_validation_scoring(model,X[current_features],y,scoring)\n",
    "            score_for_feature.append((score,feature))\n",
    "        \n",
    "        score_for_feature.sort()#ordena as pontuações de forma que o menor valor fique no início da lista\n",
    "        best_current_score,best_feature = score_for_feature.pop(score_for_feature.__len__()-1)#obtém a melhor feature junto com sua pontuação\n",
    "\n",
    "        if(detailedOutput):#se detailedOutput for True, exibe informações mais detalhadas sobre o processo\n",
    "            print('Best current score: '+str(best_current_score)+'\\nWith addition of feature: '+str(best_feature))\n",
    "\n",
    "        if current_score < (best_current_score-minScoreVariation):#se a nova pontuação - a variação mínima definida pelo usuário\n",
    "            unused_features.remove(best_feature)#for menor que a pontuação anterior, adiciona a feature às features selecionadas\n",
    "            used_features.append(best_feature)#e substitui a pontuação atual pela nova pontuação\n",
    "            current_score = best_current_score\n",
    "        elif(detailedOutput):\n",
    "                print('Rejected feature: '+best_feature+'\\nReason : Low score increase (<'+str(minScoreVariation)+')\\nFinal model has '+str(used_features.__len__())+' features')\n",
    "\n",
    "    return used_features,current_score\n",
    "\n",
    "# O código de ambas as funções foram feitos por mim, Lucas Fajardo, para um projeto durante meu intercâmbio\n",
    "# Já os comentários anteriormente estavam em inglês por culpa disso, então foram traduzidos por mim, Arthur Assis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ce40741-6e34-4f14-9e54-a879b3784e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best current score: 0.9063492063492063\n",
      "With addition of feature: Detergents_Paper\n",
      "Best current score: 0.9092063492063491\n",
      "With addition of feature: Region\n",
      "Rejected feature: Region\n",
      "Reason : Low score increase (<0.01)\n",
      "Final model has 1 features\n",
      "Selected features: ['Detergents_Paper']\n",
      "Accuracy: 0.9063492063492063\n",
      "In 1.166161298751831 Seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "features = train_data.columns.drop(\"Channel\") #Seleciona apenas a feature a serem utilizadas pelo modelo\n",
    "\n",
    "start = time() # Tempo inicial\n",
    "selected_features,acc = fwd_selection_cross_validation(X=train_data[features],y=train_data['Channel'],features=features,minScoreVariation=0.01,detailedOutput=True,scoring = 'accuracy',model= GaussianNB())\n",
    "elapsedTime = time()-start # Tempo total\n",
    "\n",
    "print('Selected features: '+str(selected_features)+'\\nAccuracy: '+str(acc)+'\\nIn '+str(elapsedTime)+' Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed5b30-d31b-4d09-979f-b95c86fd2e0e",
   "metadata": {},
   "source": [
    "O nosso modelo está apresentando uma precisão de 90.63% apenas com a feature Detergents_Paper, isso é altamente incomum, e mais pra frente com mais iremos analisar isso mais a fundo com outras métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c561e6c-81ed-4171-b1b1-0ebf7715947a",
   "metadata": {},
   "source": [
    "## EX 7\n",
    "\n",
    "Agora iremos testar a precisão do nosso modelo com os nossos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49390ed8-83b9-49fd-a3db-feeb8f45bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBmodel = GaussianNB()\n",
    "\n",
    "NBmodel.fit(train_data[selected_features],y=train_data['Channel'])\n",
    "\n",
    "Predictions = NBmodel.predict(test_data[selected_features])\n",
    "Predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cfde5-94d3-494d-995b-d36e750301c1",
   "metadata": {},
   "source": [
    "Vamos também treinar um modelo com todas as features disponíveis para ver a diferença nas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e0aeada-2830-4067-8a64-931dd7a75649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBmodelFull = GaussianNB()\n",
    "\n",
    "NBmodelFull.fit(train_data[features],y=train_data['Channel'])\n",
    "\n",
    "PredictionsFull = NBmodelFull.predict(test_data[features])\n",
    "PredictionsFull[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d49fda-f731-4ba5-b69a-a1195a1e9129",
   "metadata": {},
   "source": [
    "## Ex 8\n",
    "\n",
    "Nesse exercício iremos avaliar os nossos modelos com base em diversas métricas, a maioria obtida através da função classification_report além da acurácia dos modelos e a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13022455-3f1b-4d27-88cf-1cf9053801d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      HoReCa       0.91      0.93      0.92        54\n",
      "      Retail       0.88      0.85      0.87        34\n",
      "\n",
      "    accuracy                           0.90        88\n",
      "   macro avg       0.89      0.89      0.89        88\n",
      "weighted avg       0.90      0.90      0.90        88\n",
      "\n",
      "Accuracy: 0.8977272727272727\n",
      "Confusion matrix:\n",
      "\n",
      "[[50  4]\n",
      " [ 5 29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "\n",
    "print(classification_report(test_data[\"Channel\"],Predictions,target_names=[\"HoReCa\",\"Retail\"]))\n",
    "testAcc = accuracy_score(test_data['Channel'], Predictions)\n",
    "print('Accuracy: '+str(testAcc))\n",
    "confusionMat = confusion_matrix(test_data['Channel'], Predictions)\n",
    "print('Confusion matrix:\\n')\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e65b2-3b1d-4681-89d2-56d4666180a4",
   "metadata": {},
   "source": [
    "No geral obtivemos boas métricas, sempre com uma precisão de aproximadamente 90%, sendo excelente para um modelo tão simples quanto o Naive Bayes, ainda mais com apenas uma feature, além de recall e F1 próximos de 1 nos indicando que o nosso modelo não conseguiu métricas boas apenas \"chutando\" o mesmo valor toda vez, informação que conseguimos comprovar através da Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "996ec0b3-16fb-4e96-b072-1f7817ce427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      HoReCa       0.93      0.93      0.93        54\n",
      "      Retail       0.88      0.88      0.88        34\n",
      "\n",
      "    accuracy                           0.91        88\n",
      "   macro avg       0.90      0.90      0.90        88\n",
      "weighted avg       0.91      0.91      0.91        88\n",
      "\n",
      "Accuracy: 0.9090909090909091\n",
      "Confusion matrix:\n",
      "\n",
      "[[50  4]\n",
      " [ 4 30]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data[\"Channel\"],PredictionsFull,target_names=[\"HoReCa\",\"Retail\"]))\n",
    "testAcc = accuracy_score(test_data['Channel'], PredictionsFull)\n",
    "print('Accuracy: '+str(testAcc))\n",
    "confusionMat = confusion_matrix(test_data['Channel'], PredictionsFull)\n",
    "print('Confusion matrix:\\n')\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b915831-d4c6-4e51-81cb-092ad14255da",
   "metadata": {},
   "source": [
    "Podemos ver que as métricas obtidas utilizando um modelo com todas as features foram as mesmas das obtidas com um modelo utilizando apenas Detergents_Paper, ou seja conseguimos resultados iguais com um modelo muito mais simples, assim economizando tempo e poder computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c4406-f912-4697-8622-5365c088c3d9",
   "metadata": {},
   "source": [
    "## Ex 9\n",
    "\n",
    "Nesse exercício o usuário deve ser capaz de entrar com valores para que o modelo preveja qual o canal de vendas os dados pertencem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b027ffd-c1e6-4f77-8841-dc3c0dde3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origem prevista é HoReCa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArthurPC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prediction = NBmodel.predict([[int(input(\"Insira o valor de Detergents_Paper: \"))]])\n",
    "if prediction[0] == 0:\n",
    "    print(\"Origem prevista é HoReCa\")\n",
    "else:\n",
    "    print(\"Origem prevista é Retail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25bd10-67fe-4069-9534-9fd5037248b5",
   "metadata": {},
   "source": [
    "Vamos também fazer uma versão onde utilizamos o modelo completamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968311ac-0601-48b4-97e1-38ce2494b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origem prevista é HoTeCa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArthurPC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_features = []\n",
    "input_features.append(int(input(\"Entre com o valor de Region :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Fresh :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Milk :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Grocery :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Frozen :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Detergents_Paper :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Delicatessen :\")))\n",
    "\n",
    "prediction = NBmodelFull.predict([input_features])\n",
    "if prediction[0] == 0:\n",
    "    print(\"Origem prevista é HoReCa\")\n",
    "else:\n",
    "    print(\"Origem prevista é Retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3465ce-b8f8-41a5-8668-68c3c167a224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
