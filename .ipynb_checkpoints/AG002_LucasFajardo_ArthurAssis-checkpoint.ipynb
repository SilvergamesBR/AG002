{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474b5866-383d-4449-ac89-6f85ae7414d5",
   "metadata": {},
   "source": [
    "# AG002 - Lucas Fajardo de Mello e Arthur de Paula Assis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e684901-89c8-437e-94c5-075c46751baa",
   "metadata": {},
   "source": [
    "Para começarmos a AG primeiramente temos que carregar o nosso dataset, para isso vamos utilizar a biblioteca pandas, com a função read_csv.\n",
    "\n",
    "Vamos também importar algumas bibliotecas que utilizaremos depois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bad24b-cacc-48d8-8365-e4f7c83a648b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214              2674        1338\n",
       "1        2       3   7057  9810     9568    1762              3293        1776\n",
       "2        2       3   6353  8808     7684    2405              3516        7844\n",
       "3        1       3  13265  1196     4221    6404               507        1788\n",
       "4        2       3  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"Dataset/Wholesale customers data.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d643fe1-b3d2-40ba-80ab-f9993ae460c4",
   "metadata": {},
   "source": [
    "## Ex 3\n",
    "\n",
    "A versão baixada do link disponibilizado já estava com uma mudança similar a mudança proposta realizada, porém ná próxima célula de código iremos demonstrar como a mudança seria realizada caso necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92a3131-d769-4883-bead-58554aad0d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        1       2  12669  9656     7561     214              2674        1338\n",
       "1        1       2   7057  9810     9568    1762              3293        1776\n",
       "2        1       2   6353  8808     7684    2405              3516        7844\n",
       "3        0       2  13265  1196     4221    6404               507        1788\n",
       "4        1       2  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Channel.replace({\"HoReCa\":0,\"Retail\":1}, inplace = True) #Altera os valores HoReCa e Retail para 0 e 1\n",
    "dataset.Channel.replace({1:0,2:1}, inplace = True) #Altera os valores que estavam presentes no dataset pelos pedidos no exercicio\n",
    "\n",
    "dataset.Region.replace({\"Lisbon\":0,\"Oporto\":1,\"Other\":2}, inplace = True) #Altera os valores Lisbon, Oporto e Other para 0, 1 e 2\n",
    "dataset.Region.replace({1:0,2:1,3:2}, inplace = True) #Altera os valores que estavam presentes no dataset pelos pedidos no exercicio\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d5ed8-d1e3-4a8c-a68b-4a8972a17555",
   "metadata": {},
   "source": [
    "## Ex 4\n",
    "\n",
    "Nesse exercício iremos mudar a ordem das colunas do nosso dataframe, para isso iremos utilizar um artifício onde ao chamarmos um dataframe com uma lista das colunas desejadas em uma certa ordem o pandas retorna um dataframe com as colunas nessa mesma ordem, assim podemos atribuir esse dataframe reordenado ao original, assim o reorganizando sem a necessidade de chamadas de função mais complexas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89393cc-365f-4532-be68-aa1622208154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen  Channel\n",
       "0       2  12669  9656     7561     214              2674        1338        1\n",
       "1       2   7057  9810     9568    1762              3293        1776        1\n",
       "2       2   6353  8808     7684    2405              3516        7844        1\n",
       "3       2  13265  1196     4221    6404               507        1788        0\n",
       "4       2  22615  5410     7198    3915              1777        5185        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novaOrdem =['Region', 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen', 'Channel'] #Estabelecemos um array um com os valores na ordem nova dessejada\n",
    "\n",
    "dataset = dataset [novaOrdem] #Altera a ordem para a nova ordem desejada\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d725d-686d-4993-97bd-eb92c9baab57",
   "metadata": {},
   "source": [
    "## Ex 5\n",
    "\n",
    "Nesse exercício iremos separar nosso dataset em uma seção de teste e outra para treinos do nosso modelo de ML, iremos utilizar um split de 80/20.\n",
    "\n",
    "Para realizar essa divisão utilizaremos a função train_test_split do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7be87b-9149-4d57-a3f5-4968356af120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3c873-395d-4950-bbe7-756e1e2cb1b7",
   "metadata": {},
   "source": [
    "## Ex 6 \n",
    "\n",
    "Nesse exercício iremos escolher um modelo de ML, decidimos por escolher o modelo Naive Bayes, por ser um modelo simples baseado na matemática e que é amplamente utilizado para predições similares no contexto de varejo.\n",
    "\n",
    "Antes de treinar o nosso modelo vamos também utilizar um algoritmo de Forward Selection com K-fold cross validation para escolher apenas as features que terão um impacto significativo no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb73af27-2dce-4625-81ad-ad43ee9961a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def K_fold_validation_scoring(model,X,y,scoring:str):\n",
    "    scores = cross_val_score(model, X, y, cv=10,scoring=scoring)#does 10-fold cross validation and returns the NRMSE scores\n",
    "    return scores.mean()#returns the mean NRMSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1128d347-7643-48f7-8a91-dd60052d79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_selection_cross_validation(X,y,features,minScoreVariation : float,detailedOutput : bool,scoring : str,model):\n",
    "    used_features=[]#list to store the features should be used on our model according to forward selection \n",
    "    unused_features = list(features)#list of all the features available to our model, in the end will contain the unused features\n",
    "    current_score = float('-inf')#variable to store the score of our curent model\n",
    "    best_current_score = float('-inf')#variable to store the best score recorded\n",
    "\n",
    "    while current_score == best_current_score and unused_features:\n",
    "        score_for_feature = []#list to store the score obtained with each feature\n",
    "        for feature in unused_features:#iterates trough every unused feature and does 10-fold cross validation for each\n",
    "            current_features = used_features + [feature]\n",
    "            model.fit(X=X[current_features],y=y)\n",
    "            score = K_fold_validation_scoring(model,X[current_features],y,scoring)\n",
    "            score_for_feature.append((score,feature))\n",
    "        \n",
    "        score_for_feature.sort()#sorts the scores so the lowest value is on the beginning of the array\n",
    "        best_current_score,best_feature = score_for_feature.pop(score_for_feature.__len__()-1)#gets the best feature along with its score\n",
    "\n",
    "        if(detailedOutput):#if detailed output is set to True outputs more detailed information about the process\n",
    "            print('Best current score: '+str(best_current_score)+'\\nWith addition of feature: '+str(best_feature))\n",
    "\n",
    "        if current_score < (best_current_score-minScoreVariation):#if the new score - the minimun varition set by the user\n",
    "            unused_features.remove(best_feature)# is lower than the precious score, adds the feature to the selected features\n",
    "            used_features.append(best_feature)# and replaces the current score with the new score\n",
    "            current_score = best_current_score\n",
    "        elif(detailedOutput):\n",
    "                print('Rejected feature: '+best_feature+'\\nReason : Low score increase (<'+str(minScoreVariation)+')\\nFinal model has '+str(used_features.__len__())+' features')\n",
    "\n",
    "    return used_features,current_score\n",
    "    \n",
    "#O código de ambas as funções foram feitas por mim Lucas Fajardo, os comentários apenas estao em inglês pois fiz eles para um projeto durante meu intercâmbio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce40741-6e34-4f14-9e54-a879b3784e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best current score: 0.9034126984126984\n",
      "With addition of feature: Detergents_Paper\n",
      "Best current score: 0.9062698412698413\n",
      "With addition of feature: Region\n",
      "Rejected feature: Region\n",
      "Reason : Low score increase (<0.01)\n",
      "Final model has 1 features\n",
      "Selected features: ['Detergents_Paper']\n",
      "Accuracy: 0.9034126984126984\n",
      "In 0.28357553482055664 Seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "features = train_data.columns.drop(\"Channel\") #Seleciona apenas a feature a serem utilizadas pelo modelo\n",
    "\n",
    "start = time() # Tempo inicial\n",
    "selected_features,acc = fwd_selection_cross_validation(X=train_data[features],y=train_data['Channel'],features=features,minScoreVariation=0.01,detailedOutput=True,scoring = 'accuracy',model= GaussianNB())\n",
    "elapsedTime = time()-start # Tempo total\n",
    "\n",
    "print('Selected features: '+str(selected_features)+'\\nAccuracy: '+str(acc)+'\\nIn '+str(elapsedTime)+' Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed5b30-d31b-4d09-979f-b95c86fd2e0e",
   "metadata": {},
   "source": [
    "O nosso modelo está apresentando uma precisão de 90.34% com apenas a feature Detergents_Paper, isso é altamente incomum, e mais pra frente com mais métricas iremos analizar isso mais a fundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c561e6c-81ed-4171-b1b1-0ebf7715947a",
   "metadata": {},
   "source": [
    "## EX 7\n",
    "\n",
    "Agora iremos testar a precisão do nosso modelo com os nossos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49390ed8-83b9-49fd-a3db-feeb8f45bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBmodel = GaussianNB()\n",
    "\n",
    "NBmodel.fit(train_data[selected_features],y=train_data['Channel'])\n",
    "\n",
    "Predictions = NBmodel.predict(test_data[selected_features])\n",
    "Predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cfde5-94d3-494d-995b-d36e750301c1",
   "metadata": {},
   "source": [
    "Vamos também treinar um modelo com todas as features disponíveis para ver a diferença nas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e0aeada-2830-4067-8a64-931dd7a75649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBmodelFull = GaussianNB()\n",
    "\n",
    "NBmodelFull.fit(train_data[features],y=train_data['Channel'])\n",
    "\n",
    "PredictionsFull = NBmodelFull.predict(test_data[features])\n",
    "PredictionsFull[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d49fda-f731-4ba5-b69a-a1195a1e9129",
   "metadata": {},
   "source": [
    "## Ex 8\n",
    "\n",
    "Nesse exercício iremos avaliar os nossos modelos com base em diversas métricas, a maioria obtida através da função classification_report além da acurácia dos modelos e a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13022455-3f1b-4d27-88cf-1cf9053801d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      HoTeCa       0.94      0.94      0.94        65\n",
      "      Retail       0.83      0.83      0.83        23\n",
      "\n",
      "    accuracy                           0.91        88\n",
      "   macro avg       0.88      0.88      0.88        88\n",
      "weighted avg       0.91      0.91      0.91        88\n",
      "\n",
      "Accuracy: 0.9090909090909091\n",
      "Confusion matrix:\n",
      "\n",
      "[[61  4]\n",
      " [ 4 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "\n",
    "print(classification_report(test_data[\"Channel\"],Predictions,target_names=[\"HoTeCa\",\"Retail\"]))\n",
    "testAcc = accuracy_score(test_data['Channel'], Predictions)\n",
    "print('Accuracy: '+str(testAcc))\n",
    "confusionMat = confusion_matrix(test_data['Channel'], Predictions)\n",
    "print('Confusion matrix:\\n')\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e65b2-3b1d-4681-89d2-56d4666180a4",
   "metadata": {},
   "source": [
    "No geral obtivemos boas métricas, com uma precisão acima de 90%, sendo excelende para um modelo tão simples quanto o naive bayes, ainda mais com apenas uma feature, além de recall e F1 próximos de 1 nos indicando que o nosso modelo não conseguiu métricas boas apenas \"chutando\" o mesmo valor toda vez, informação que conseguimos comprovar através da confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "996ec0b3-16fb-4e96-b072-1f7817ce427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      HoTeCa       0.94      0.94      0.94        65\n",
      "      Retail       0.83      0.83      0.83        23\n",
      "\n",
      "    accuracy                           0.91        88\n",
      "   macro avg       0.88      0.88      0.88        88\n",
      "weighted avg       0.91      0.91      0.91        88\n",
      "\n",
      "Accuracy: 0.9090909090909091\n",
      "Confusion matrix:\n",
      "\n",
      "[[61  4]\n",
      " [ 4 19]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data[\"Channel\"],PredictionsFull,target_names=[\"HoTeCa\",\"Retail\"]))\n",
    "testAcc = accuracy_score(test_data['Channel'], PredictionsFull)\n",
    "print('Accuracy: '+str(testAcc))\n",
    "confusionMat = confusion_matrix(test_data['Channel'], PredictionsFull)\n",
    "print('Confusion matrix:\\n')\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b915831-d4c6-4e51-81cb-092ad14255da",
   "metadata": {},
   "source": [
    "Podemos ver que as métricas obtidas utilizando um modelo com todas as features foram as mesmas das obtidas com um modelo utilizando apenas Detergents_Paper, ou seja conseguimos resultados iguais com um modelo muito mais simples, assim economizando tempo e poder computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c4406-f912-4697-8622-5365c088c3d9",
   "metadata": {},
   "source": [
    "## Ex 9\n",
    "\n",
    "Nesse exercício o usuário deve ser capaz de entrar com valores para que o modelo preveja qual o canal de vendas a qual os dados pertencem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b027ffd-c1e6-4f77-8841-dc3c0dde3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insira o valor de Detergents_Paper:  3565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origem prevista é Retail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\anaconda3\\envs\\data_mining\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prediction = NBmodel.predict([[int(input(\"Insira o valor de Detergents_Paper: \"))]])\n",
    "if prediction[0] == 0:\n",
    "    print(\"Origem prevista é HoTeCa\")\n",
    "else:\n",
    "    print(\"Origem prevista é Retail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25bd10-67fe-4069-9534-9fd5037248b5",
   "metadata": {},
   "source": [
    "Vamos também fazer uma versão onde utilizamos a versão completa do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "968311ac-0601-48b4-97e1-38ce2494b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre com o valor de Region : 2\n",
      "Entre com o valor de Fresh : 2\n",
      "Entre com o valor de Milk : 2\n",
      "Entre com o valor de Grocery : 2\n",
      "Entre com o valor de Frozen : 2\n",
      "Entre com o valor de Detergents_Paper : 2\n",
      "Entre com o valor de Delicatessen : 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origem prevista é HoTeCa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\anaconda3\\envs\\data_mining\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_features = []\n",
    "input_features.append(int(input(\"Entre com o valor de Region :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Fresh :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Milk :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Grocery :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Frozen :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Detergents_Paper :\")))\n",
    "input_features.append(int(input(\"Entre com o valor de Delicatessen :\")))\n",
    "\n",
    "prediction = NBmodelFull.predict([input_features])\n",
    "if prediction[0] == 0:\n",
    "    print(\"Origem prevista é HoTeCa\")\n",
    "else:\n",
    "    print(\"Origem prevista é Retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3465ce-b8f8-41a5-8668-68c3c167a224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
